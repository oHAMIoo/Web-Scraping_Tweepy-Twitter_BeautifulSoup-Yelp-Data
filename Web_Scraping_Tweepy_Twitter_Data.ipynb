{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Web Scraping_Tweepy Twitter Data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7Cvv2jtAxL7"
      },
      "source": [
        "# Scraping Users tweets with Tweepy API\n",
        "In this project, I scraped a timeline of tweets and printed each one of the tweets to an excel file. </br>\n",
        "**Note:** Twitter requires all requests to use OAuth for authentication. The Authentication requires a user to register with the Twitter Developer Account."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJgWHZsv--sj",
        "outputId": "62942f8a-61e8-4df3-9612-5af75393b40e"
      },
      "source": [
        "import tweepy\n",
        "import csv \n",
        "#create authentication for accessing Twitter    \n",
        "consumer_key = input('Consumer Key ') # L0HNflcwaA9cK4cwZEu8E0RhO <<<(This is my twitter key)\n",
        "consumer_secret = input('Consumer Secret ') # MxYGzrBFAAlPrbc1S6KsgEVQ8VZqwUscPca5P2UkQfCK4VQKTn\n",
        "access_token = input('Access Token ') # 702743084157816832-cWAvyvXQF8vc5UVrlcSwEHtykiU6SlO\n",
        "access_token_secret = input('Access Token Secret ') # 05mCyT1W7M1X3mZBh3d9USnH9J0Et2oUUdt1IGj7s86Zi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "L0HNflcwaA9cK4cwZEu8E0RhOL0HNflcwaA9cK4cwZEu8E0RhO\n",
            "MxYGzrBFAAlPrbc1S6KsgEVQ8VZqwUscPca5P2UkQfCK4VQKTnMxYGzrBFAAlPrbc1S6KsgEVQ8VZqwUscPca5P2UkQfCK4VQKTn\n",
            "702743084157816832-cWAvyvXQF8vc5UVrlcSwEHtykiU6SlO702743084157816832-cWAvyvXQF8vc5UVrlcSwEHtykiU6SlO\n",
            "05mCyT1W7M1X3mZBh3d9USnH9J0Et2oUUdt1IGj7s86Zi05mCyT1W7M1X3mZBh3d9USnH9J0Et2oUUdt1IGj7s86Zi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqMHyWwSFQB0"
      },
      "source": [
        "# OAuth Authenticationn\n",
        "With token received"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0yiftTM_yEL",
        "outputId": "50b09521-81ab-40cc-a42b-f0f54bd75cdf"
      },
      "source": [
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "\n",
        "#initialize Tweepy API (application programming interface)\n",
        "api = tweepy.API(auth)\n",
        "\n",
        "#output to csv file \n",
        "def search_term(outputFile, term, limit):\n",
        "\n",
        "    result = open(outputFile, 'a')\n",
        "    csvWriter = csv.writer(result)\n",
        "    csvWriter.writerow([\"Screen Name\", \"Number of Followers\", \"Location\", \"Tweet\"])\n",
        "\n",
        "    try:\n",
        "        i = 0\n",
        "        for tweet in tweepy.Cursor(api.search,\n",
        "                                    q = term,\n",
        "                                    lang = \"en\").items(limit):\n",
        "\n",
        "            csvWriter.writerow([tweet.user.screen_name, \n",
        "                                tweet.user.followers_count, \n",
        "                                tweet.user.location, \n",
        "                                tweet.text.encode('utf-8')])\n",
        "            i = i+1\n",
        "        print(str(i)+\" rows of data crawled from Twitter related to \" + term)\n",
        "\n",
        "        result.close()\n",
        "    except:\n",
        "        print(\"Waiting to crawl...\")\n",
        "        print(\"Done crawling, check directory folder.\")\n",
        "\n",
        "        \n",
        "# Data to crawl with the application\n",
        "first_hashtag = input('1st Hastag')  # For my first hashtag, I used BasketBall\n",
        "Second_hashtag = input('2nd Hastag') # For my second hashtag, I used Champion\n",
        "number_result = int(input('Number of results')) # I chose to view 150 results.\n",
        "        \n",
        "search_term(first_hashtag, Second_hashtag, number_result)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1st HastagBasketBall\n",
            "2nd HastagChampion\n",
            "Number of results150\n",
            "Waiting to crawl...\n",
            "Done crawling, check directory folder.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}